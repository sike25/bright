## Bright

Bright takes in a natural language prompt and, in response to it, generates a song you can see. 
I built it in JavaScript with the D3 library, the Web Audio API, and the Suno API. 

**[See Demo on Loom](https://www.loom.com/share/dc349655a7e24a35a454d39c0d4b34c6?sid=5c8b2f4a-e1ee-46d5-9df8-1377d5196117)**

---
![bright_back](https://github.com/user-attachments/assets/47534b0d-9559-484b-89a9-9b0b712614a8)

### Inspiration

Nigeria enjoys an inventive and successful music industry. 
Making music in Nigeria, especially today, can be surprisingly democratic. 
College students produce beats on the weekends. Local church choirs release their own albums.

Recently, I read about The [Sound Color](https://soundcolorproject.com/) project by Kevin Groat and Derek Torsani, 
which was created to use color to bring the experience of music to people without great hearing.

I thought visualization could be more than a way to allow people to see music. 
It can also be a way for them to create music. 
And because color and sound have infinite functions that map between their many representations, this was also a technically fascinating question.


### Next for Bright
Simultaneous video generation alongside the audio.                
A canvas feature that will let users create music by painting onto a screen.           
There is no incredible, open-source sound-to-visuals converter. 
I want to build one, especially incorporating ideas and feels from both 
[synthesia realities](https://en.wikipedia.org/wiki/Synesthesia) and [VJ-ing practices](https://en.wikipedia.org/wiki/VJing).           
